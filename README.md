# Projet MLOps : Classification d'Images - Pissenlits vs Herbe

## ğŸ¯ Objectif du Projet

Ce projet implÃ©mente un pipeline MLOps complet pour la classification binaire d'images, distinguant les pissenlits (dandelion) de l'herbe (grass). Il dÃ©montre l'application pratique des principes MLOps avec TensorFlow, incluant l'entraÃ®nement automatisÃ©, le dÃ©ploiement, le monitoring et l'intÃ©gration continue.

## ğŸ“‹ Table des MatiÃ¨res

- [Architecture du Projet](#architecture-du-projet)
- [PrÃ©requis](#prÃ©requis)
- [Installation](#installation)
- [Structure du Projet](#structure-du-projet)
- [Utilisation](#utilisation)
- [Environnements](#environnements)
- [Pipeline MLOps](#pipeline-mlops)
- [API et WebApp](#api-et-webapp)
- [Monitoring](#monitoring)
- [Tests](#tests)
- [DÃ©ploiement](#dÃ©ploiement)
- [Contributions](#contributions)

## ğŸ—ï¸ Architecture du Projet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Source   â”‚â”€â”€â”€â–¶â”‚   Apache        â”‚â”€â”€â”€â–¶â”‚   ML Model      â”‚
â”‚   (MySQL DB)    â”‚    â”‚   Airflow       â”‚    â”‚   Training      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Monitoring    â”‚    â”‚   CI/CD         â”‚    â”‚   Model         â”‚
â”‚   (Prometheus)  â”‚    â”‚   (GitHub       â”‚    â”‚   Registry      â”‚
â”‚                 â”‚    â”‚   Actions)      â”‚    â”‚   (S3/MLflow)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   WebApp        â”‚    â”‚   Kubernetes    â”‚    â”‚   FastAPI       â”‚
â”‚   (Streamlit)   â”‚    â”‚   Deployment    â”‚    â”‚   Serving       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ PrÃ©requis

- **Python 3.8+**
- **Docker & Docker Compose**
- **Kubernetes** (Minikube ou Docker Desktop)
- **Git**

### Technologies UtilisÃ©es

| Composant | Technologie |
|-----------|-------------|
| **ML Framework** | TensorFlow 2.x |
| **Orchestration** | Apache Airflow |
| **API** | FastAPI |
| **WebApp** | Streamlit |
| **Model Registry** | MLflow |
| **Storage** | AWS S3 (Minio) |
| **Database** | MySQL |
| **Monitoring** | Prometheus + Grafana |
| **CI/CD** | GitHub Actions |
| **Containerization** | Docker |
| **Deployment** | Kubernetes |

## ğŸš€ Installation

### 1. Cloner le repository

```bash
git clone https://github.com/TM-Squared/mlops_image-classification.git
cd mlops_image-classification
```

### 2. Environnement de dÃ©veloppement

```bash
# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### 3. Configuration avec Docker Compose

```bash
# Lancer l'environnement complet
docker-compose up -d

# VÃ©rifier les services
docker-compose ps
```

## ğŸ“ Structure du Projet

```
mlops_image-classification/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py      # Chargement des donnÃ©es
â”‚   â”‚   â””â”€â”€ preprocessing.py    # PrÃ©processing des images
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ model.py           # DÃ©finition du modÃ¨le
â”‚   â”‚   â””â”€â”€ training.py        # EntraÃ®nement
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py           # FastAPI application
â”‚   â”‚   â””â”€â”€ schemas.py        # ModÃ¨les Pydantic
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py         # Configuration
â”‚       â””â”€â”€ logger.py         # Logging
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ data_pipeline.py  # Pipeline d'extraction
â”‚   â”‚   â”œâ”€â”€ training_pipeline.py  # Pipeline d'entraÃ®nement
â”‚   â”‚   â””â”€â”€ inference_pipeline.py # Pipeline d'infÃ©rence
â”‚   â””â”€â”€ plugins/
â”œâ”€â”€ webapp/
â”‚   â”œâ”€â”€ app.py               # Application Streamlit
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_data_loader.py
â”‚   â”‚   â”œâ”€â”€ test_model.py
â”‚   â”‚   â””â”€â”€ test_api.py
â”‚   â””â”€â”€ integration/
â”‚       â””â”€â”€ test_pipeline.py
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.api
â”‚   â”œâ”€â”€ Dockerfile.webapp
â”‚   â””â”€â”€ Dockerfile.airflow
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ namespace.yaml
â”‚   â”œâ”€â”€ api-deployment.yaml
â”‚   â”œâ”€â”€ webapp-deployment.yaml
â”‚   â””â”€â”€ monitoring/
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â””â”€â”€ prometheus.yml
â”‚   â””â”€â”€ grafana/
â”‚       â””â”€â”€ dashboards/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml
â”‚       â”œâ”€â”€ cd.yml
â”‚       â””â”€â”€ tests.yml
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ® Utilisation

### 1. PrÃ©paration des donnÃ©es

```bash
# Initialiser la base de donnÃ©es
python src/data/init_db.py

# Lancer le pipeline d'extraction
python src/data/data_loader.py
```

### 2. EntraÃ®nement du modÃ¨le

```bash
# EntraÃ®nement local
python src/models/training.py

# Ou via Airflow
# AccÃ©der Ã  http://localhost:8080
# DÃ©clencher le DAG "training_pipeline"
```

### 3. Lancement de l'API

```bash
# Mode dÃ©veloppement
uvicorn src.api.main:app --reload --port 8000

# AccÃ©der Ã  la documentation : http://localhost:8000/docs
```

### 4. WebApp Streamlit

```bash
# Lancer l'application
streamlit run webapp/app.py

# AccÃ©der Ã  : http://localhost:8501
```

## ğŸŒ Environnements

### DÃ©veloppement (Local)
- **Services** : Docker Compose
- **Base de donnÃ©es** : MySQL local
- **Storage** : MinIO local
- **Monitoring** : Prometheus + Grafana locaux

### Production (Kubernetes)
- **Orchestration** : Kubernetes (Minikube/Cloud)
- **Base de donnÃ©es** : MySQL avec persistance
- **Storage** : S3 compatible
- **Monitoring** : Stack Prometheus complet
- **Ingress** : Nginx Ingress Controller

## ğŸ”„ Pipeline MLOps

### 1. Pipeline de DonnÃ©es (`data_pipeline.py`)
- Extraction des images depuis les URLs
- Validation et nettoyage des donnÃ©es
- Stockage dans S3
- Mise Ã  jour des mÃ©tadonnÃ©es

### 2. Pipeline d'EntraÃ®nement (`training_pipeline.py`)
- Chargement des donnÃ©es depuis S3
- PrÃ©processing et augmentation
- EntraÃ®nement du modÃ¨le TensorFlow
- Ã‰valuation et validation
- Sauvegarde du modÃ¨le dans MLflow

### 3. Pipeline de DÃ©ploiement (`inference_pipeline.py`)
- TÃ©lÃ©chargement du meilleur modÃ¨le
- DÃ©ploiement automatique de l'API
- Tests de santÃ© du service
- Monitoring des performances

### 4. EntraÃ®nement Continu (CT)
- **Triggers** :
  - Nouvelles donnÃ©es disponibles
  - EntraÃ®nement hebdomadaire programmÃ©
  - DÃ©gradation des performances dÃ©tectÃ©e
- **Actions** :
  - RÃ©-entraÃ®nement automatique
  - Validation A/B testing
  - DÃ©ploiement conditionnel

## ğŸš¦ API et WebApp

### API FastAPI

**Endpoints principaux :**
- `POST /predict` : PrÃ©diction sur une image
- `GET /health` : SantÃ© du service  
- `GET /metrics` : MÃ©triques Prometheus
- `GET /model/info` : Informations sur le modÃ¨le

**Exemple d'utilisation :**
```python
import requests

# PrÃ©diction
files = {"file": open("image.jpg", "rb")}
response = requests.post("http://localhost:8000/predict", files=files)
print(response.json())
```

### WebApp Streamlit

**FonctionnalitÃ©s :**
- Interface de tÃ©lÃ©chargement d'images
- Affichage des prÃ©dictions en temps rÃ©el
- Visualisation des mÃ©triques du modÃ¨le
- Historique des prÃ©dictions

## ğŸ“Š Monitoring

### MÃ©triques CollectÃ©es

1. **MÃ©triques Applicatives**
   - Nombre de prÃ©dictions
   - Latence des requÃªtes
   - Accuracy du modÃ¨le
   - Distributions des prÃ©dictions

2. **MÃ©triques SystÃ¨me**
   - Utilisation CPU/RAM
   - Espace disque
   - Statut des services

3. **MÃ©triques Business**
   - Taux d'utilisation
   - Temps de rÃ©ponse utilisateur
   - DisponibilitÃ© du service

### Dashboards Grafana

- **Dashboard Principal** : Vue d'ensemble des services
- **Dashboard ML** : MÃ©triques spÃ©cifiques au modÃ¨le
- **Dashboard Infrastructure** : Monitoring systÃ¨me

### Alertes

- Service indisponible
- DÃ©gradation des performances
- Erreurs d'entraÃ®nement
- Espace disque faible

## ğŸ§ª Tests

### Tests Unitaires

```bash
# Lancer tous les tests
pytest tests/unit/

# Tests spÃ©cifiques
pytest tests/unit/test_model.py -v
```

### Tests d'IntÃ©gration

```bash
# Tests end-to-end
pytest tests/integration/

# Tests avec couverture
pytest --cov=src tests/
```

### Tests de Charge

```bash
# Installer Locust
pip install locust

# Lancer les tests
locust -f tests/load/locustfile.py --host=http://localhost:8000
```

## ğŸš€ DÃ©ploiement

### DÃ©ploiement Local (Kubernetes)

```bash
# DÃ©marrer Minikube
minikube start

# DÃ©ployer l'application
kubectl apply -f k8s/

# VÃ©rifier les dÃ©ploiements
kubectl get pods
kubectl get services
```

### DÃ©ploiement Cloud (Optionnel)

```bash
# Configurer kubectl pour votre cluster cloud
# DÃ©ployer avec Helm
helm install mlops-app ./helm/mlops-chart
```


## ğŸ¤ Contributions

1. **Fork** le repository
2. **CrÃ©er** une branche feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** vos changements (`git commit -m 'Add some AmazingFeature'`)
4. **Push** vers la branche (`git push origin feature/AmazingFeature`)
5. **Ouvrir** une Pull Request

## ğŸ“ License

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ‘¥ Ã‰quipe

- **Nom du Team** : TOUSSI ManoÃ«l Malaury
- **Contact** : [manoel@malaurytoussi.cm]


## ğŸ“š Ressources SupplÃ©mentaires

### Choix Techniques

**Pourquoi TensorFlow ?**
- Excellent support pour la classification d'images
- IntÃ©gration native avec TensorFlow Serving
- Ã‰cosystÃ¨me mature pour la production

**Pourquoi FastAPI ?**
- Performance Ã©levÃ©e (basÃ© sur Starlette)
- Documentation automatique (Swagger)
- Validation des donnÃ©es native

**Pourquoi Airflow ?**
- Orchestration robuste des pipelines
- Interface graphique intuitive
- Gestion des dÃ©pendances complexes

### Optimisations RÃ©alisÃ©es

1. **ModÃ¨le** :
   - Transfer learning avec MobileNetV2
   - Augmentation des donnÃ©es
   - Early stopping et callbacks

2. **API** :
   - Mise en cache des modÃ¨les
   - Traitement asynchrone
   - Validation des entrÃ©es

3. **Infrastructure** :
   - RÃ©partition de charge
   - Monitoring proactif
   - Scaling automatique

---

*Ce README sera maintenu Ã  jour avec les Ã©volutions du projet. N'hÃ©sitez pas Ã  contribuer Ã  son amÃ©lioration !*