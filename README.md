# ğŸŒ± Plant Classification MLOps

**Classification d'images de plantes (Pissenlit vs Herbe) avec pipeline MLOps complet**

![Python](https://img.shields.io/badge/Python-3.10-blue)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13-orange)
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-2.10.1-red)
![Docker](https://img.shields.io/badge/Docker-Compose-blue)
![MLflow](https://img.shields.io/badge/MLflow-2.7.1-green)
![MinIO](https://img.shields.io/badge/MinIO-S3-yellow)

## ğŸ“‹ Table des MatiÃ¨res

- [AperÃ§u du Projet](#aperÃ§u-du-projet)
- [Architecture](#architecture)
- [Technologies UtilisÃ©es](#technologies-utilisÃ©es)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [API Documentation](#api-documentation)
- [Tests](#tests)
- [Monitoring](#monitoring)
- [DÃ©ploiement](#dÃ©ploiement)
- [Contribution](#contribution)

## AperÃ§u du Projet

Ce projet implÃ©mente un pipeline MLOps complet pour la classification binaire d'images de plantes, distinguant les dandelion de l'herbe (grass). Il dÃ©montre les meilleures pratiques MLOps incluant l'automatisation, le monitoring, et le dÃ©ploiement continu.

### FonctionnalitÃ©s Principales

- **ğŸ¤– Classification automatique** d'images avec TensorFlow/MobileNetV2
- **ğŸ“Š Pipeline d'entraÃ®nement** automatisÃ© avec Apache Airflow
- **ğŸ—„ï¸ Stockage distribuÃ©** avec MinIO (compatible S3)
- **ğŸ“ˆ Tracking d'expÃ©riences** avec MLflow
- **ğŸŒ API REST** avec FastAPI
- **ğŸ’» Interface web** avec Streamlit
- **ğŸ”„ EntraÃ®nement continu** et dÃ©ploiement automatique
- **ğŸ³ Containerisation** complÃ¨te avec Docker

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚    â”‚   Data Storage  â”‚    â”‚   Processing    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ GitHub URLs   â”‚â”€â”€â”€â–¶â”‚ â€¢ MinIO (S3)    â”‚â”€â”€â”€â–¶â”‚ â€¢ Apache Airflowâ”‚
â”‚ â€¢ Manual Upload â”‚    â”‚ â€¢ MySQL         â”‚    â”‚ â€¢ TensorFlow    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Monitoring    â”‚    â”‚   Model Store   â”‚    â”‚   ML Training   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ MLflow UI     â”‚â—€â”€â”€â”€â”‚ â€¢ MinIO Models  â”‚â—€â”€â”€â”€â”‚ â€¢ Model Trainingâ”‚
â”‚ â€¢ Logs          â”‚    â”‚ â€¢ Model Registryâ”‚    â”‚ â€¢ Evaluation    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Interfaceâ”‚    â”‚   API Layer     â”‚    â”‚   Deployment    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Streamlit App â”‚â”€â”€â”€â–¶â”‚ â€¢ FastAPI       â”‚â—€â”€â”€â”€â”‚ â€¢ Auto Deploy   â”‚
â”‚ â€¢ Web Interface â”‚    â”‚ â€¢ REST Endpointsâ”‚    â”‚ â€¢ Model Serving â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Technologies UtilisÃ©es

### Machine Learning & Data
- **TensorFlow 2.13** - Framework de deep learning
- **MobileNetV2** - ModÃ¨le de transfer learning lÃ©ger
- **MLflow** - Tracking d'expÃ©riences et registry de modÃ¨les
- **Pandas/NumPy** - Manipulation de donnÃ©es

### Infrastructure & Orchestration
- **Apache Airflow** - Orchestration de pipelines
- **Docker & Docker Compose** - Containerisation
- **MinIO** - Stockage objet compatible S3
- **MySQL** - Base de donnÃ©es relationnelle
- **PostgreSQL** - Base de donnÃ©es Airflow

### API & Interface
- **FastAPI** - API REST moderne et rapide
- **Streamlit** - Interface web interactive
- **Uvicorn** - Serveur ASGI haute performance

### DevOps & Monitoring
- **GitHub Actions** - CI/CD (prÃªt pour dÃ©ploiement)
- **pytest** - Framework de tests
- **Logging** - Monitoring et debugging

## ğŸš€ Installation

### PrÃ©requis

- Docker & Docker Compose
- Git
- 8GB RAM minimum
- 10GB espace disque libre

### Installation Rapide

```bash
# 1. Cloner le repository
git clone <votre-repo-url>
cd plant-classification-mlops

# 2. CrÃ©er le fichier d'environnement
cp .env.example .env

# 3. CrÃ©er les dossiers nÃ©cessaires
mkdir -p airflow/logs models tests/data

# 4. Lancer l'environnement
docker-compose up --build -d

# 5. Attendre le dÃ©marrage (2-3 minutes)
docker-compose logs -f
```

### Configuration des Variables d'Environnement

Modifier le fichier `.env` selon vos besoins :

```bash
# Base de donnÃ©es
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow123
MYSQL_USER=plants_user
MYSQL_PASSWORD=plants123

# MinIO
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin123

# Airflow
AIRFLOW_USERNAME=admin
AIRFLOW_PASSWORD=admin123
```

## Utilisation

### 1. Premier DÃ©marrage

AprÃ¨s le lancement, configurez les connexions Airflow :

```bash
# AccÃ©der Ã  Airflow
open http://localhost:8080
# Login: admin / admin123

# DÃ©clencher le DAG "setup_connections" pour configurer automatiquement les connexions
```

### 2. Pipeline d'Ingestion de DonnÃ©es

```bash
# Dans Airflow UI, activer et dÃ©clencher :
# 1. "plants_data_ingestion_pipeline" - Ingestion des donnÃ©es
# 2. "model_training_minio_pipeline" - EntraÃ®nement du modÃ¨le
```

### 3. Test de l'API

```bash
# VÃ©rifier l'API
curl http://localhost:8000/health

# Tester une prÃ©diction
curl -X POST "http://localhost:8000/predict-url" \
  -H "Content-Type: application/json" \
  -d '{"image_url": "https://raw.githubusercontent.com/btphan95/greenr-airflow/refs/heads/master/data/dandelion/00000000.jpg"}'
```

### 4. Interface Web

```bash
# AccÃ©der Ã  la WebApp
open http://localhost:8501
```

## ğŸ”Œ API Documentation

### Endpoints Principaux

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/` | GET | Informations sur l'API |
| `/health` | GET | Statut de santÃ© |
| `/predict` | POST | PrÃ©diction via upload |
| `/predict-url` | POST | PrÃ©diction via URL |
| `/models` | GET | Liste des modÃ¨les |
| `/reload-model` | POST | Recharger le modÃ¨le |

### Exemple d'Utilisation

```python
import requests

# PrÃ©diction via URL
response = requests.post(
    "http://localhost:8000/predict-url",
    params={"image_url": "https://example.com/image.jpg"}
)

result = response.json()
print(f"Classe prÃ©dite: {result['predicted_class']}")
print(f"Confiance: {result['confidence']:.2%}")
```

### Documentation Interactive

La documentation Swagger est disponible Ã  : `http://localhost:8000/docs`

## Tests

### Lancer les Tests

```bash
# Tests unitaires
docker-compose exec airflow-webserver python -m pytest tests/ -v

# Tests d'intÃ©gration
docker-compose exec api python -m pytest tests/ -v

# Tests end-to-end
python tests/test_e2e.py
```

### Coverage

```bash
# GÃ©nÃ©rer un rapport de couverture
docker-compose exec airflow-webserver python -m pytest tests/ --cov=ml --cov-report=html
```

## ğŸ“Š Monitoring

### Interfaces de Monitoring

- **Airflow** : `http://localhost:8080` - Monitoring des DAGs
- **MLflow** : `http://localhost:5000` - Tracking des expÃ©riences
- **MinIO Console** : `http://localhost:9001` - Gestion du stockage
- **API Docs** : `http://localhost:8000/docs` - Documentation API

### Logs

```bash
# Logs en temps rÃ©el
docker-compose logs -f

# Logs spÃ©cifiques
docker-compose logs airflow-scheduler
docker-compose logs api
```

### MÃ©triques Importantes

- **PrÃ©cision du modÃ¨le** : Suivi dans MLflow
- **Temps de rÃ©ponse API** : Logs FastAPI
- **Utilisation stockage** : Console MinIO
- **Statut des DAGs** : Interface Airflow

## ğŸš¢ DÃ©ploiement

### Environnement de Production

```bash
# Utiliser le fichier de production
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d

# Ou dÃ©ployment Kubernetes (manifests dans k8s/)
kubectl apply -f k8s/
```

### CI/CD avec GitHub Actions

Le pipeline CI/CD est configurÃ© dans `.github/workflows/` et inclut :

- Tests automatiques
- Build et push des images Docker
- DÃ©ploiement automatique
- Tests de santÃ© post-dÃ©ploiement

### Variables de Production

```bash
# Production .env
POSTGRES_PASSWORD=<strong-password>
MYSQL_PASSWORD=<strong-password>
MINIO_SECRET_KEY=<strong-secret>
AIRFLOW_PASSWORD=<strong-password>
```

## ğŸ”§ DÃ©pannage

### ProblÃ¨mes Courants

**1. Erreur de permissions MinIO**
```bash
# VÃ©rifier les clÃ©s d'accÃ¨s
docker-compose logs minio
# RecrÃ©er les connexions Airflow
```

**2. ModÃ¨le non trouvÃ©**
```bash
# VÃ©rifier les modÃ¨les dans MinIO
curl http://localhost:8000/models
# Relancer l'entraÃ®nement
```

**3. Erreur de base de donnÃ©es**
```bash
# RÃ©initialiser les bases
docker-compose down -v
docker-compose up --build -d
```

### Support

Pour obtenir de l'aide :
1. VÃ©rifiez les [issues GitHub](../../issues)
2. Consultez les logs : `docker-compose logs`
3. Ouvrez une nouvelle issue avec les dÃ©tails

## ğŸ‘¥ Contribution

### Guide de Contribution

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit vos changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

### Standards de Code

- **Format** : Black pour Python
- **Linting** : Flake8
- **Tests** : pytest avec coverage > 80%
- **Documentation** : Docstrings pour toutes les fonctions

### Structure des Commits

```
type(scope): description

- feat: nouvelle fonctionnalitÃ©
- fix: correction de bug
- docs: documentation
- test: ajout de tests
- refactor: refactoring
```

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.


